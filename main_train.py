# main_train.py (æœ€ç»ˆç‰ˆ - v5.0 é›†æˆæ™ºèƒ½å®éªŒæ¡£æ¡ˆç³»ç»Ÿ)
#
# --- v5.0 æ›´æ–° (æ¡£æ¡ˆç³»ç»Ÿé›†æˆ) ---
# 1. åœ¨ main å‡½æ•°çš„å¼€å¤´ï¼Œæˆ‘ä»¬ä¸å†è°ƒç”¨æ—§çš„ setup_loggerã€‚
# 2. åœ¨ main_worker çš„å¼€å¤´ï¼Œæˆ‘ä»¬ç°åœ¨è°ƒç”¨æ–°çš„ setup_experiment å‡½æ•°ï¼š
#    - è¿™ä¼šç«‹å³åˆ›å»ºæœ¬æ¬¡å®éªŒçš„ä¸“å±æ–‡ä»¶å¤¹ï¼ˆä¾‹å¦‚ 'experiments/20251104-...')ã€‚
#    - åŒæ—¶ä¼šè‡ªåŠ¨é…ç½®å¥½æ—¥å¿—ï¼Œä½¿å…¶åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œè¯¥æ–‡ä»¶å¤¹ä¸‹çš„ 'training_log.txt'ã€‚
#    - æˆ‘ä»¬è¿˜ä¼šç«‹å³å°†ä½ ä½¿ç”¨çš„ .yaml é…ç½®æ–‡ä»¶å¤åˆ¶ä¸€ä»½å­˜æ¡£åˆ°è¯¥æ–‡ä»¶å¤¹ã€‚
# 3. åœ¨æ¨¡å‹ä¿å­˜é€»è¾‘ä¸­ï¼Œæ‰€æœ‰è·¯å¾„ç°åœ¨éƒ½ä½¿ç”¨ setup_experiment è¿”å›çš„ experiment_dir ä½œä¸ºæ ¹ç›®å½•ã€‚
# 4. è¿™ç¡®ä¿äº†æ¯ä¸€æ¬¡è¿è¡Œï¼Œæ‰€æœ‰çš„äº§ç‰©ï¼ˆæ¨¡å‹ã€æ—¥å¿—ã€é…ç½®ï¼‰éƒ½è¢«å®Œç¾åœ°ã€åŸå­åŒ–åœ°ä¿å­˜åœ¨åŒä¸€ä¸ªåœ°æ–¹ã€‚

import os
import torch
import multiprocessing as mp

mp.set_start_method('spawn', force=True)
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader

import logging
from tqdm import tqdm
import argparse

# [!!!] å¯¼å…¥æˆ‘ä»¬æ–°çš„å·¥å…·å‡½æ•°
from core.utils import load_config, setup_experiment, save_config_to_experiment_dir, AverageMeter, accuracy
from core.dataset import PoisonedDataset
from core.models.resnet import ResNet18 as ModelToUse


def main():
    parser = argparse.ArgumentParser(description='S2A Backdoor Attack Training (Online Poisoning)')
    parser.add_argument('--config', default='./configs/gtsrb_64x64_random.yaml', help='è·¯å¾„åˆ° YAML é…ç½®æ–‡ä»¶')
    args = parser.parse_args()

    config = load_config(args.config)
    # [!!!] setup_logger() å·²è¢«ç§»é™¤ï¼Œæ–°çš„è®¾ç½®å°†åœ¨ main_worker ä¸­è¿›è¡Œ

    device_str = config.get('device', 'cuda:0' if torch.cuda.is_available() else 'cpu')
    device = torch.device(device_str)

    if not torch.cuda.is_available() and device_str.startswith('cuda'):
        # logging åœ¨ setup_experiment ä¸­é…ç½®ï¼Œä½†æˆ‘ä»¬å¯ä»¥åœ¨è¿™ä¹‹å‰ç”¨ print åº”æ€¥
        print("é”™è¯¯: CUDA ä¸å¯ç”¨ï¼Œä½†è®¾å¤‡è¢«è®¾ç½®ä¸ºCUDAã€‚")
        device = torch.device('cpu')

    # å°† args ä¼ é€’ä¸‹å»ï¼Œæˆ‘ä»¬éœ€è¦åŸå§‹çš„ config è·¯å¾„æ¥å­˜æ¡£
    main_worker(device, config, args)


def main_worker(device, config, args):
    # [!!! æ ¸å¿ƒä¿®æ”¹ 1: åˆ›å»ºå®éªŒæ–‡ä»¶å¤¹å¹¶è®¾ç½®æ—¥å¿— !!!]
    experiment_dir = setup_experiment(config)

    # [!!! æ ¸å¿ƒä¿®æ”¹ 2: å­˜æ¡£æœ¬æ¬¡å®éªŒä½¿ç”¨çš„é…ç½®æ–‡ä»¶ !!!]
    save_config_to_experiment_dir(args.config, experiment_dir)

    logging.info(f"æœ¬æ¬¡å®éªŒçš„æ‰€æœ‰äº§ç‰©å°†è¢«ä¿å­˜åœ¨: {experiment_dir}")
    logging.info(f"æ­£åœ¨ä½¿ç”¨è®¾å¤‡: {device}")

    # --- åç»­ä»£ç å‡ ä¹ä¸å˜ï¼Œé™¤äº†ä¿å­˜è·¯å¾„ ---

    logging.info(f"ä½¿ç”¨æ¨¡å‹: {ModelToUse.__name__}")
    data_path = config['dataset']['data_path']
    logging.info(f"æ‰€æœ‰åŸå§‹æ•°æ®é›†å°†è¢«ä¸‹è½½åˆ° .yaml æ–‡ä»¶æŒ‡å®šçš„è·¯å¾„: {data_path}")
    if not os.path.exists(data_path):
        os.makedirs(data_path)

    logging.info("ä½¿ç”¨åœ¨çº¿ä¸­æ¯’æ¨¡å¼åŠ è½½è®­ç»ƒé›†...")
    train_dataset = PoisonedDataset(config, train=True, poison=True)

    train_loader = DataLoader(
        train_dataset, batch_size=config['train']['batch_size'], shuffle=True,
        num_workers=config['train'].get('num_workers', 0), pin_memory=True
    )

    logging.info("åŠ è½½éªŒè¯é›† (C-ACC å’Œ ASR)...")
    val_clean_dataset = PoisonedDataset(config, train=False, poison=False)
    val_clean_loader = DataLoader(val_clean_dataset, batch_size=config['train']['batch_size'] * 2,
                                  shuffle=False, num_workers=config['train'].get('num_workers', 0))

    val_asr_dataset = PoisonedDataset(config, train=False, asr_eval=True)
    val_asr_loader = DataLoader(val_asr_dataset, batch_size=config['train']['batch_size'] * 2,
                                shuffle=False, num_workers=config['train'].get('num_workers', 0))

    dataset_name = config['dataset']['name']
    model = ModelToUse(num_classes=config['dataset']['num_classes'], dataset_name=dataset_name).to(device)

    criterion = nn.CrossEntropyLoss().to(device)

    train_config = config['train']
    optimizer_name = train_config['optimizer'].lower()
    logging.info(f"ä»é…ç½®æ–‡ä»¶è¯»å–åˆ°ä¼˜åŒ–å™¨: {optimizer_name}")
    if optimizer_name == 'sgd':
        optimizer = optim.SGD(model.parameters(), lr=train_config['learning_rate'], momentum=train_config['momentum'],
                              weight_decay=train_config['weight_decay'])
    elif optimizer_name == 'adamw':
        optimizer = optim.AdamW(model.parameters(), lr=train_config['learning_rate'],
                                weight_decay=train_config['weight_decay'])
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ä¼˜åŒ–å™¨: {optimizer_name}. è¯·åœ¨ 'sgd' æˆ– 'adamw' ä¸­é€‰æ‹©ã€‚")

    scheduler_name = train_config['scheduler'].lower()
    num_epochs = train_config['epochs']
    logging.info(f"ä»é…ç½®æ–‡ä»¶è¯»å–åˆ°è°ƒåº¦å™¨: {scheduler_name}")
    if scheduler_name == 'cosine':
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)
    elif scheduler_name == 'multistep':
        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=train_config['milestones'], gamma=0.1)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è°ƒåº¦å™¨: {scheduler_name}. è¯·åœ¨ 'cosine' æˆ– 'multistep' ä¸­é€‰æ‹©ã€‚")

    logging.info("--- å¼€å§‹è®­ç»ƒ ---")
    best_ba_under_high_asr = 0.0
    asr_at_best_ba = 0.0
    best_epoch = 0
    best_model_save_path = ""

    for epoch in range(num_epochs):
        train_one_epoch(train_loader, model, criterion, optimizer, epoch, device)

        clean_acc = validate(val_clean_loader, model, criterion, device, "C-ACC")
        asr = -1.0

        current_epoch = epoch + 1
        if current_epoch > 50 or current_epoch == num_epochs:
            asr = validate(val_asr_loader, model, criterion, device, "ASR")

        print()
        asr_log_str = f"{asr:.2f}%" if asr != -1.0 else " (è·³è¿‡)"
        logging.info(f"--- Epoch {current_epoch}/{num_epochs} --- "
                     f"C-ACC (BA): {clean_acc:.2f}% | ASR: {asr_log_str} | "
                     f"LR: {scheduler.get_last_lr()[0]:.5f}")

        if asr > 99.0:
            if clean_acc > best_ba_under_high_asr:
                best_ba_under_high_asr = clean_acc
                asr_at_best_ba = asr
                best_epoch = current_epoch

                # [!!! æ ¸å¿ƒä¿®æ”¹ 3: ä¿å­˜è·¯å¾„ä½¿ç”¨ experiment_dir !!!]
                model_filename = (f'checkpoint_{dataset_name}_{ModelToUse.__name__}'
                                  f'_asr{asr:.2f}_ba{clean_acc:.2f}.pth')
                new_save_path = os.path.join(experiment_dir, model_filename)

                logging.info(
                    f"ğŸ† æ–°çš„å† å†›æ¨¡å‹è¯ç”Ÿ (ASR>99%): BA: {clean_acc:.2f}%, ASR: {asr:.2f}%. ä¿å­˜è‡³è¯¥å®éªŒæ–‡ä»¶å¤¹å†… ğŸ†")
                torch.save({'epoch': current_epoch, 'model_state_dict': model.state_dict()}, new_save_path)

                if best_model_save_path and os.path.exists(best_model_save_path):
                    os.remove(best_model_save_path)

                best_model_save_path = new_save_path

        scheduler.step()

    logging.info("\n" + "=" * 50)
    logging.info("--- è®­ç»ƒå®Œæˆï¼šæœ€ç»ˆè¯„ä¼°æ€»ç»“ ---")
    logging.info("=" * 50)
    if best_epoch > 0:
        logging.info(f"ğŸ† æœ€ç»ˆå† å†›æ¨¡å‹ (ASR > 99% ä¸” BA æœ€é«˜):")
        logging.info(f"   - åœ¨ Epoch {best_epoch} è·å¾—")
        logging.info(f"   - æœ€ä½³ BA: {best_ba_under_high_asr:.2f}%")
        logging.info(f"   - å¯¹åº” ASR: {asr_at_best_ba:.2f}%")
        logging.info(f"   - æ¨¡å‹å’Œæ—¥å¿—å·²ä¿å­˜åœ¨: {experiment_dir}")
    else:
        logging.warning("âš ï¸ è­¦å‘Š: åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒASRæœªèƒ½è¾¾åˆ°99%çš„ä¿å­˜æ ‡å‡†ã€‚")
        logging.warning(f"   - æ²¡æœ‰ä¿å­˜ä»»ä½•æ¨¡å‹ã€‚æ—¥å¿—å’Œé…ç½®å·²ä¿å­˜åœ¨: {experiment_dir}")
    logging.info("=" * 50)


# train_one_epoch å’Œ validate å‡½æ•°ä¿æŒä¸å˜
def train_one_epoch(loader, model, criterion, optimizer, epoch, device):
    losses, top1 = AverageMeter(), AverageMeter()
    model.train()
    progress_bar = tqdm(loader, desc=f"è®­ç»ƒ Epoch {epoch + 1}", leave=False)
    for i, (images, target) in enumerate(progress_bar):
        images, target = images.to(device, non_blocking=True), target.to(device, non_blocking=True)
        output = model(images)
        loss = criterion(output, target)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        acc1, _ = accuracy(output, target, topk=(1, 5))
        losses.update(loss.item(), images.size(0))
        top1.update(acc1[0].item(), images.size(0))
        progress_bar.set_postfix(Loss=f"{losses.avg:.4f}", Acc=f"{top1.avg:.2f}%")


def validate(loader, model, criterion, device, eval_type="Eval"):
    losses, top1 = AverageMeter(), AverageMeter()
    model.eval()
    progress_bar = tqdm(loader, desc=f"è¯„ä¼° {eval_type}", leave=False)
    with torch.no_grad():
        for (images, target) in progress_bar:
            images, target = images.to(device, non_blocking=True), target.to(device, non_blocking=True)
            output = model(images)
            loss = criterion(output, target)
            acc1, _ = accuracy(output, target, topk=(1, 5))
            losses.update(loss.item(), images.size(0))
            top1.update(acc1[0].item(), images.size(0))
            progress_bar.set_postfix(Loss=f"{losses.avg:.4f}", Acc=f"{top1.avg:.2f}%")
    return top1.avg


if __name__ == '__main__':
    main()